# -*- coding: utf-8 -*-
"""1771078_정드림_홍채_2차_코드.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XbzI321dBivfEfiTOQeTm2cbDW2lFXJ8
"""

from glob import glob
import imageio
import cv2
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score 

import keras
from keras import backend as K
from keras import layers
from keras.layers import Input,Add,Dense,Activation, Flatten,Conv2D,AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, MaxPooling2D, Dropout,ZeroPadding2D
from keras.layers.normalization import BatchNormalization
from keras.models import Model,load_model
from keras.models import Sequential
from keras import optimizers
from keras.initializers import glorot_uniform
from keras.callbacks import EarlyStopping,ModelCheckpoint
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers


#https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/

import os,sys
from google.colab import drive

drive.mount('/content/mnt')

!unzip /content/mnt/MyDrive/dataset/03_iris_training.zip -d /content/mnt/MyDrive/dataset/iris_training
!unzip /content/mnt/MyDrive/dataset/03_iris_test.zip -d /content/mnt/MyDrive/dataset/iris_test

label=[]
for i in range(1,65):
  for j in range(2):
      label.append(i)
print(label)

y_arr=np.array(label)
print(y_arr.shape)

#y_arr=np.concatenate([y_arr,y_arr])
#y_arr.shape

trainpath='/content/mnt/MyDrive/dataset/iris_training/*'
traindata=glob(trainpath)

imgheight=224
imgwidth=224

def readImages(data):
  images=[]
  for i in range(len(data)):
    img=cv2.imread(data[i])
    img=img[:,70:700]
    img=cv2.resize(img,(imgwidth,imgheight))
    images.append(img)
  return images
trainingimages=[]
trainingimages=readImages(traindata)

#images1=tf.image.flip_left_right(trainingimages)
#trainingimages=np.concatenate([trainingimages,images1])

images_arr = np.asarray(trainingimages)
images_arr = images_arr.astype('float32')
images_arr=images_arr.reshape(-1,imgwidth,imgheight,3) ####
images_arr=images_arr/255
images_arr.shape

path='/content/mnt/MyDrive/dataset/iris_test/'
file_names=os.listdir(path)
for file_name in file_names:
  src=os.path.join(path,file_name)
  dst=file_name.zfill(7)
  dst=os.path.join(path,dst)
  os.rename(src,dst)

testpath='/content/mnt/MyDrive/dataset/iris_test/*'
realdata=glob(testpath)
realdata.sort()
realimages=[]
realimages=readImages(realdata)

#https://sims-solve.tistory.com/19  파일이름 일괄변경

realimages_arr = np.asarray(realimages)
realimages_arr = realimages_arr.astype('float32')
realimages_arr = realimages_arr.reshape(-1,imgwidth,imgheight,3) ####
realimages_arr = realimages_arr/255

realimages_arr.shape

for i in range(20,25):
    plt.figure(figsize = (12,12))
    plt.subplot(5, 5, i+1)
    plt.imshow(images_arr[i+200])
    plt.axis('off')
    plt.tight_layout()
    plt.show()

class conv_block(tf.keras.Model):
    def __init__(self, filters, strides=(2, 2)):
        super(conv_block, self).__init__()

        self.filters1, self.filters2, self.filters3 = filters
        self.strides = strides

        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=strides)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.relu1 = tf.keras.layers.ReLU()

        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.relu2 = tf.keras.layers.ReLU()

        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))
        self.bn3 = tf.keras.layers.BatchNormalization()

        self.shortcut_conv = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=strides)
        self.shortcut_bn = tf.keras.layers.BatchNormalization()

        self.add = tf.keras.layers.Add()
        self.add_relu = tf.keras.layers.ReLU()


    def call(self, input_tensor, training=False):
        x = self.conv1(input_tensor)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu2(x)

        x = self.conv3(x)
        x = self.bn3(x)

        shortcut = self.shortcut_conv(input_tensor)
        shortcut = self.shortcut_bn(shortcut)

        x = self.add([x, shortcut])
        x = self.add_relu(x)

        return x
        


class identity_block(tf.keras.Model):
    def __init__(self, filters):
        super(identity_block, self).__init__()

        self.filters1, self.filters2, self.filters3 = filters

        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=(1, 1))
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.relu1 = tf.keras.layers.ReLU()

        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.relu2 = tf.keras.layers.ReLU()

        self.conv3 = tf.keras.layers.Conv2D(self.filters3, (1, 1), strides=(1, 1))
        self.bn3 = tf.keras.layers.BatchNormalization()
        
        self.add = tf.keras.layers.Add()
        self.add_relu = tf.keras.layers.ReLU()

    
    def call(self, input_tensor, training=False):
        x = self.conv1(input_tensor)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu2(x)

        x = self.conv3(x)
        x = self.bn3(x)

        x = self.add([x, input_tensor])
        x = self.add_relu(x)

        return x


    
class ResNet50(tf.keras.Model):
    def __init__(self, nb_classes):
        super(ResNet50, self).__init__()
        self.nb_classes = nb_classes

        # Stage 1 (Conv1 Layer)
        self.zero_padd_1_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))
        self.conv_1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))
        self.bn_1 = tf.keras.layers.BatchNormalization()
        self.relu_1 = tf.keras.layers.ReLU()
        self.zero_padd_1_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))
        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))

        # Stage 2
        self.stage2 = tf.keras.Sequential()
        self.stage2.add(conv_block([64, 64, 256], strides=(1, 1)))
        self.stage2.add(identity_block([64, 64, 256]))
        self.stage2.add(identity_block([64, 64, 256]))

        # Stage 3
        self.stage3 = tf.keras.Sequential()
        self.stage3.add(conv_block([128, 128, 512]))
        self.stage3.add(identity_block([128, 128, 512]))
        self.stage3.add(identity_block([128, 128, 512]))
        self.stage3.add(identity_block([128, 128, 512]))

        # Stage 4
        self.stage4 = tf.keras.Sequential()
        self.stage4.add(conv_block([256, 256, 1024]))
        self.stage4.add(identity_block([256, 256, 1024]))
        self.stage4.add(identity_block([256, 256, 1024]))
        self.stage4.add(identity_block([256, 256, 1024]))
        self.stage4.add(identity_block([256, 256, 1024]))
        self.stage4.add(identity_block([256, 256, 1024]))

        # Stage 5
        self.stage5 = tf.keras.Sequential()
        self.stage5.add(conv_block([512, 512, 2048]))
        self.stage5.add(identity_block([512, 512, 2048]))
        self.stage5.add(identity_block([512, 512, 2048]))


        self.gap = tf.keras.layers.GlobalAveragePooling2D()
        self.dense = tf.keras.layers.Dense(self.nb_classes, activation='softmax')


    def call(self, input_tensor, training=False):
        x = self.zero_padd_1_1(input_tensor)
        x = self.conv_1(x)
        x = self.bn_1(x)
        x = self.relu_1(x)
        x = self.zero_padd_1_2(x)
        x = self.max_pool(x)

        x = self.stage2(x)
        x = self.stage3(x)
        x = self.stage4(x)
        x = self.stage5(x)

        x = self.gap(x)
        x = self.dense(x)

        return x 


model = ResNet50(65)
model.build((1, 224,224, 3))
model.summary()

md=tf.keras.applications.ResNet101V2(
    include_top=True,
    input_tensor=None,
    weights=None,
    input_shape=None,
    pooling=None,
    classes=65,
    classifier_activation="softmax",
)

ep=20
bs=16
md.compile(optimizer=optimizers.Adam(learning_rate=0.000001),loss='categorical_crossentropy',
              metrics=['acc'])
accuracy=[]
recall=[]
precision=[]
f1score=[]
kfold = KFold(n_splits=4,shuffle=True)
i=1
for train_index, validate_index in kfold.split(images_arr,y_arr):
  print(i,' step')
  X_train, X_val = images_arr[train_index], images_arr[validate_index]
  y_train, y_val = y_arr[train_index], y_arr[validate_index]
  y_true=y_val
  y_train=tf.keras.utils.to_categorical(y_train,65)
  y_val=tf.keras.utils.to_categorical(y_val,65)
  history=md.fit(X_train,y_train,batch_size=bs,
                    validation_data=(X_val,y_val),epochs=ep)
  pred=md.predict(X_val)
  valpred=tf.argmax(pred,1)

  accuracy.append(accuracy_score(y_true,valpred))
  recall.append(recall_score(y_true,valpred,average='macro'))
  precision.append(precision_score(y_true,valpred,average='macro'))
  f1score.append(f1_score(y_true,valpred,average='macro'))
  i+=1

acc = history.history['acc']
val_acc = history.history['val_acc']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(ep)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

print(accuracy)
print(recall)
print(precision)
print(f1score)

predictions=md.predict(realimages_arr)
correct_prediction=tf.argmax(predictions,1)
print(correct_prediction)

from google.colab import files
df=pd.DataFrame(correct_prediction)
df

df.to_csv('irisresnet101v2.txt')
files.download('irisresnet101v2.txt')